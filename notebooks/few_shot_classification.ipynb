{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Surprise similarity for text classification\n",
    "install the surprise_similarity package with:\n",
    " `pip install surprise_similarity`"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data preparation\n",
    "We'll use the datasets library to load the Yahoo! Answers dataset.  Once we've loaded the dataset we select a subset of the training data to use for our few-shot training.  (We actually select several subsets for statistical signficance.) We then for training/test datasets as lists of (input, target) tuples to train and evaluate our classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/.conda/envs/surprise2/lib/python3.9/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "# Set a random seed for dataset reproducability\n",
    "import random\n",
    "random.seed(666)\n",
    "from datasets import load_dataset\n",
    "\n",
    "\n",
    "dataset_input_target_mapping = {\"yahoo_answers_topics\": (\"question_title\", \"topic\")}\n",
    "\n",
    "# get standardized train/test dataframes with columns \"input\" and \"targets\" \n",
    "# and a list of all possible targets\n",
    "def prepare_dataset(dataset_name=\"yahoo_answers_topics\"):\n",
    "    ds = load_dataset(dataset_name)\n",
    "    df_train = ds[\"train\"].to_pandas()\n",
    "    df_test = ds[\"test\"].to_pandas()\n",
    "    df_train.rename(\n",
    "        columns={dataset_input_target_mapping[dataset_name][0]: \"inputs\"}, inplace=True\n",
    "    )\n",
    "    df_test.rename(\n",
    "        columns={dataset_input_target_mapping[dataset_name][0]: \"inputs\"}, inplace=True\n",
    "    )\n",
    "\n",
    "    int_to_text_target = {\n",
    "        i: v\n",
    "        for i, v in enumerate(\n",
    "            ds[\"train\"].features[dataset_input_target_mapping[dataset_name][1]].names\n",
    "        )\n",
    "    }\n",
    "    label_set = list(int_to_text_target.values())\n",
    "\n",
    "    train_targets = [\n",
    "        int_to_text_target[i] if isinstance(i, int) else i\n",
    "        for i in df_train[dataset_input_target_mapping[dataset_name][1]]\n",
    "    ]\n",
    "    test_targets = [\n",
    "        int_to_text_target[i] if isinstance(i, int) else i\n",
    "        for i in df_test[dataset_input_target_mapping[dataset_name][1]]\n",
    "    ]\n",
    "    df_train[\"targets\"] = train_targets\n",
    "    df_test[\"targets\"] = test_targets\n",
    "    return df_train, df_test, label_set\n",
    "\n",
    "# get few-shot training and test data\n",
    "def prepare_training_data(\n",
    "    df_train,\n",
    "    df_test,\n",
    "    label_set,\n",
    "    train_samples_per_label,\n",
    "    random_seed,\n",
    "    balanced_training=True,\n",
    "):\n",
    "    test_input_output = list(zip(df_test[\"inputs\"], df_test[\"targets\"]))\n",
    "    training_input_output = []\n",
    "    if balanced_training:\n",
    "        for label in label_set:\n",
    "            df_tmp = df_train.loc[df_train.targets == label].sample(\n",
    "                train_samples_per_label, random_state=random_seed\n",
    "            )\n",
    "            training_input_output.extend(list(zip(df_tmp[\"inputs\"], df_tmp[\"targets\"])))\n",
    "    else:\n",
    "        df_tmp = df_train.sample(\n",
    "            train_samples_per_label * len(label_set), random_state=random_seed\n",
    "        )\n",
    "        training_input_output.extend(list(zip(df_tmp[\"inputs\"], df_tmp[\"targets\"])))\n",
    "    return training_input_output, test_input_output"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training\n",
    "We will train a SurpriseSimilarity classifier on the Yahoo! Answers few-shot datasets and evaluate on the full test set using both F1 and accuracy as metrics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import f1_score, accuracy_score\n",
    "from surprise_similarity import SurpriseSimilarity\n",
    "\n",
    "# Use sklearn's f1_score and accuracy_score to evaluate the model\n",
    "def f1(x, y):\n",
    "    return f1_score(x, y, average=\"weighted\", zero_division=0)\n",
    "\n",
    "# Train the model on the training data and evaluate on the test data, return f1 and accuracy\n",
    "def train_and_run_on_testset(\n",
    "    training_data,\n",
    "    test_data,\n",
    "):\n",
    "    ss = SurpriseSimilarity()\n",
    "    training_data = random.sample(training_data, len(training_data))\n",
    "    ss.train(\n",
    "        keys=[item[0] for item in training_data],\n",
    "        queries=[item[1] for item in training_data],\n",
    "        shuffle=False,  # defaults to true, use False here for better reproducability\n",
    "    )\n",
    "    if ss.max_itns:\n",
    "        print(\"Reached max iterations\")\n",
    "    print(\"Starting prediction on testset\")\n",
    "    predictions = ss.predict(\n",
    "        keys=[item[0] for item in test_data],\n",
    "        queries=list(set([item[1] for item in test_data])),\n",
    "    )\n",
    "    f1_result = f1([it[1] for it in test_data], predictions)\n",
    "    acc_result = accuracy_score([it[1] for it in test_data], predictions)\n",
    "    return f1_result, acc_result"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run experiments\n",
    "We would like to the performance of the SurpriseSimilarity classifier as a function of the number of few-shot training examples.  We would also like to know how this performance vaires depending on the specific training examples that are selected, so we run 5 experiments per training sample size to estimate 1 standard deviation error bars.  \n",
    "\n",
    "This takes a while - for a quick experiment, reduce the maximum value in `train_samples_per_label_lis` or `n_runs_per_train_size`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def execute_few_shot_experiment(train_samples_per_label_list=[3, 9, 27, 81, 243, 729],\n",
    "                                n_runs_per_train_size=5,\n",
    "                                dataset_name='yahoo_answers_topics',\n",
    "                                balanced_training=True,\n",
    "                                ):\n",
    "    df_train, df_test, label_set = prepare_dataset(dataset_name=dataset_name)\n",
    "\n",
    "    results_per_train_size = {num: {'f1': [], 'acc': []} for num in train_samples_per_label_list}\n",
    "    for train_samples_per_label in train_samples_per_label_list:\n",
    "        print(f'Starting {n_runs_per_train_size} runs for {train_samples_per_label} training samples per label')\n",
    "        for run_count in range(n_runs_per_train_size):\n",
    "            print(f'Starting run {run_count}')\n",
    "            train_io, test_io = prepare_training_data(df_train=df_train,\n",
    "                                                      df_test=df_test,\n",
    "                                                      label_set=label_set,\n",
    "                                                      train_samples_per_label=train_samples_per_label,\n",
    "                                                      random_seed=run_count,\n",
    "                                                      balanced_training=balanced_training,\n",
    "                                                      )\n",
    "            f1_result, acc_result = train_and_run_on_testset(training_data=train_io,\n",
    "                                                            test_data=test_io,\n",
    "                                                            )\n",
    "            results_per_train_size[train_samples_per_label]['f1'].append(f1_result)\n",
    "            results_per_train_size[train_samples_per_label]['acc'].append(acc_result)\n",
    "    return results_per_train_size"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Found cached dataset yahoo_answers_topics (/home/ubuntu/.cache/huggingface/datasets/yahoo_answers_topics/yahoo_answers_topics/1.0.0/0edb353eefe79d9245d7bd7cac5ae6af19530439da520d6dde1c206ee38f4439)\n",
      "100%|██████████| 2/2 [00:00<00:00, 93.37it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5 runs for 3 training samples per label\n",
      "Starting run 0\n",
      "Training on 300 examples...\n",
      "\n",
      "Training time: 0:20min (9 iterations, F1: 0.9)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.31it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1\n",
      "Training on 300 examples...\n",
      "\n",
      "Training time: 0:16min (8 iterations, F1: 0.933)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.67it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 2\n",
      "Training on 300 examples...\n",
      "\n",
      "Training time: 0:14min (8 iterations, F1: 0.9)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:27<00:00, 66.99it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 3\n",
      "Training on 300 examples...\n",
      "\n",
      "Training time: 0:17min (9 iterations, F1: 0.967)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.47it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 4\n",
      "Training on 300 examples...\n",
      "\n",
      "Training time: 0:18min (9 iterations, F1: 0.967)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.80it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5 runs for 9 training samples per label\n",
      "Starting run 0\n",
      "Training on 900 examples...\n",
      "\n",
      "Training time: 0:32min (5 iterations, F1: 0.911)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1\n",
      "Training on 900 examples...\n",
      "\n",
      "Training time: 0:31min (5 iterations, F1: 0.944)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.51it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 2\n",
      "Training on 900 examples...\n",
      "\n",
      "Training time: 0:28min (5 iterations, F1: 0.911)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.81it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 3\n",
      "Training on 900 examples...\n",
      "\n",
      "Training time: 0:30min (5 iterations, F1: 0.944)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.83it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 4\n",
      "Training on 900 examples...\n",
      "\n",
      "Training time: 0:29min (5 iterations, F1: 0.933)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.73it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5 runs for 27 training samples per label\n",
      "Starting run 0\n",
      "Training on 2700 examples...\n",
      "\n",
      "Training time: 1:10min (4 iterations, F1: 0.967)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.95it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1\n",
      "Training on 2700 examples...\n",
      "\n",
      "Training time: 1:10min (4 iterations, F1: 0.941)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 2\n",
      "Training on 2700 examples...\n",
      "\n",
      "Training time: 1:07min (4 iterations, F1: 0.97)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.63it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 3\n",
      "Training on 2700 examples...\n",
      "\n",
      "Training time: 1:10min (4 iterations, F1: 0.981)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 4\n",
      "Training on 2700 examples...\n",
      "\n",
      "Training time: 0:52min (3 iterations, F1: 0.911)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.86it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5 runs for 81 training samples per label\n",
      "Starting run 0\n",
      "Training on 8100 examples...\n",
      "\n",
      "Training time: 2:32min (3 iterations, F1: 0.957)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.60it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1\n",
      "Training on 8100 examples...\n",
      "\n",
      "Training time: 2:34min (3 iterations, F1: 0.972)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.88it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 2\n",
      "Training on 8100 examples...\n",
      "\n",
      "Training time: 2:34min (3 iterations, F1: 0.968)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 3\n",
      "Training on 8100 examples...\n",
      "\n",
      "Training time: 2:37min (3 iterations, F1: 0.984)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.65it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 4\n",
      "Training on 8100 examples...\n",
      "\n",
      "Training time: 2:34min (3 iterations, F1: 0.965)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.61it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting 5 runs for 243 training samples per label\n",
      "Starting run 0\n",
      "Training on 24280 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 76/76 [00:01<00:00, 61.45it/s]\n",
      "Batches: 100%|██████████| 76/76 [00:01<00:00, 68.27it/s]\n",
      "Batches: 100%|██████████| 76/76 [00:01<00:00, 67.76it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training time: 5:06min (2 iterations, F1: 0.919)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1874/1874 [00:28<00:00, 66.72it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 1\n",
      "Training on 24290 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 76/76 [00:01<00:00, 66.53it/s]\n",
      "Batches: 100%|██████████| 76/76 [00:01<00:00, 67.67it/s]\n",
      "Batches: 100%|██████████| 76/76 [00:01<00:00, 67.49it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training time: 5:06min (2 iterations, F1: 0.93)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1874/1874 [00:28<00:00, 66.59it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 2\n",
      "Training on 24290 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 76/76 [00:01<00:00, 66.40it/s]\n",
      "Batches: 100%|██████████| 76/76 [00:01<00:00, 67.47it/s]\n",
      "Batches: 100%|██████████| 76/76 [00:01<00:00, 66.90it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training time: 5:07min (2 iterations, F1: 0.931)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1875/1875 [00:28<00:00, 66.84it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 3\n",
      "Training on 24280 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 76/76 [00:01<00:00, 66.51it/s]\n",
      "Batches: 100%|██████████| 76/76 [00:01<00:00, 67.22it/s]\n",
      "Batches: 100%|██████████| 76/76 [00:01<00:00, 66.96it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training time: 5:11min (2 iterations, F1: 0.923)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1874/1874 [00:27<00:00, 67.10it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Starting run 4\n",
      "Training on 24300 examples...\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 76/76 [00:01<00:00, 67.04it/s]\n",
      "Batches: 100%|██████████| 76/76 [00:01<00:00, 68.35it/s]\n",
      "Batches: 100%|██████████| 76/76 [00:01<00:00, 67.89it/s]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Training time: 5:06min (2 iterations, F1: 0.929)\n",
      "Starting prediction on testset\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Batches: 100%|██████████| 1874/1874 [00:27<00:00, 66.93it/s]\n"
     ]
    }
   ],
   "source": [
    "balanced_few_shot_results = execute_few_shot_experiment([3, 9, 27, 81, 243])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "f1_means = []\n",
    "f1_error_bars = []\n",
    "acc_means = []\n",
    "acc_error_bars = []\n",
    "for k,v in balanced_few_shot_results.items():\n",
    "    f1_means.append(np.mean(v['f1']))\n",
    "    f1_error_bars.append(np.std(v['f1']))\n",
    "    acc_means.append(np.mean(v['acc']))\n",
    "    acc_error_bars.append(np.std(v['acc']))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "training e.g. per label       F1             Acc      \n",
      "------------------------------------------------------------\n",
      "         3               0.635±0.004         0.637±0.004\n",
      "         9               0.667±0.003         0.668±0.003\n",
      "         27              0.682±0.004         0.684±0.004\n",
      "         81              0.688±0.002         0.689±0.002\n",
      "         243             0.698±0.002         0.7±0.002\n"
     ]
    }
   ],
   "source": [
    "print('training e.g. per label', '      F1      ', '      Acc      ')\n",
    "print('-'*60)\n",
    "for i, k in enumerate(balanced_few_shot_results.keys()):\n",
    "    print(f'         {k}'+' '*(7-len(str(k))),\n",
    "          f'        {round(f1_means[i],3)}'+u\"\\u00B1\"+f'{round(f1_error_bars[i],3)}',\n",
    "          f'        {round(acc_means[i],3)}'+u\"\\u00B1\"+f'{round(acc_error_bars[i],3)}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.16"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
